// ================================
// MongoDB â€” Advanced Aggregation & Query Examples + Notes
// ================================

// === THEORY / Overview ===
// Aggregation in MongoDB uses a _pipeline_ model: the output of one stage becomes input to the next.
// Common pipeline stages include: $match, $project, $group, $sort, $limit, $skip, $unwind, $lookup, $bucket / $bucketAuto, $facet, $set / $addFields / $unset, $setWindowFields (from newer versions) etc.
// Aggregation is used for analytics, reporting, data transformation, joining collections, histogram / bucketing, windowed computations, and more â€” especially when simple find() isnâ€™t enough.

// ================================
// EXAMPLE AGGREGATION PIPELINES
// ================================

1. Group + sum/avg + sort + limit â€” e.g. top customers or products by total amount
db.orders.aggregate([
  { $match: { status: "completed", orderDate: { $gte: ISODate("2025-01-01") } } },
  { $group: {
      _id: "$customerId",
      totalSpent: { $sum: "$amount" },
      avgOrderValue: { $avg: "$amount" },
      orderCount: { $sum: 1 }
    }
  },
  { $sort: { totalSpent: -1 } },
  { $limit: 10 }
]);

2. Unwind an array field + group â€” e.g. count frequency of array items across documents
db.users.aggregate([
  { $unwind: "$likes" },
  { $group: {
      _id: "$likes",
      count: { $sum: 1 }
    }
  },
  { $sort: { count: -1 } },
  { $limit: 5 }
]);

3. Join (lookup) + project â€” for merging data from two collections (like SQL JOIN)
db.orders.aggregate([
  { $match: { status: "completed" } },
  { $lookup: {
      from: "products",
      localField: "productId",
      foreignField: "_id",
      as: "productDetails"
    }
  },
  { $unwind: "$productDetails" },
  { $project: {
      _id: 1,
      customerId: 1,
      amount: 1,
      "productDetails.name": 1,
      "productDetails.category": 1
    }
  }
]);

4. Multi-branch aggregation using $facet â€” compute several independent aggregates in one query
db.orders.aggregate([
  { $facet: {
      totalOrders: [ { $count: "count" } ],
      completedOrders: [ { $match: { status: "completed" } }, { $count: "count" } ],
      averageAmount: [ { $group: { _id: null, avgAmount: { $avg: "$amount" } } } ]
    }
  }
]);

5. Bucketing / histogram â€” group numeric or date fields into ranges (manual buckets)
db.customers.aggregate([
  { $bucket: {
      groupBy: "$age",
      boundaries: [18, 25, 35, 50, 65],
      default: "65+",
      output: {
        count: { $sum: 1 },
        avgSpending: { $avg: "$spending" }
      }
    }
  }
]);

6. Automatic bucketing using $bucketAuto â€” Mongo computes buckets for you based on distribution
db.sales.aggregate([
  { $bucketAuto: {
      groupBy: "$amount",
      buckets: 5,
      output: {
         count: { $sum: 1 },
         totalSales: { $sum: "$amount" }
      }
    }
  }
]);

7. Window functions (on MongoDB â‰¥ 5.0) â€” e.g. running totals, moving averages per partition/sort key
db.sales.aggregate([
  { $sort: { date: 1 } },
  { $setWindowFields: {
      partitionBy: "$productId",
      sortBy: { date: 1 },
      output: {
        cumulativeSales: { $sum: "$quantity", window: { documents: ["unbounded", "current"] } },
        avgLast3: { $avg: "$quantity", window: { documents: [-2, "current"] } }
      }
    }
  }
]);

8. Combine multiple collections using $unionWith â€” e.g. unify records from two collections and then aggregate
db.collection1.aggregate([
  /* some pipeline on collection1 */
  { $unionWith: "collection2" },
  /* further pipeline on combined results */
  { $match: { status: "active" } },
  { $group: { _id: "$category", count: { $sum: 1 } } }
]);

9. Persist aggregated results into another collection â€” using $merge or $out (materialized view / summary collection)
db.orders.aggregate([
  { $group: { _id: "$status", totalAmount: { $sum: "$amount" } } },
  { $merge: { into: "orderSummary", whenMatched: "merge", whenNotMatched: "insert" } }
]);

10. Example: Monthly sales totals (by extracting month from date field + grouping)
db.sales.aggregate([
  { $addFields: { month: { $month: "$date" } } },
  { $group: { _id: "$month", total: { $sum: "$amount" } } },
  { $sort: { _id: 1 } }
]);

// ================================
// NOTES / BEST PRACTICES / CONSIDERATIONS
// ================================
// - Always try to $match (filter) early in the pipeline to reduce number of documents processed downstream.
// - Use projection ($project / $addFields / $unset) to limit fields you carry forward â€” reduces memory usage.
// - For large data sets or memory-intensive pipelines, consider using option { allowDiskUse: true } in .aggregate() to allow disk spill.
// - Use $lookup judiciously; joining large collections may be expensive. Sometimes embedding or precomputed data / denormalization might be better depending on access patterns. (Design tradeoffs apply).
// - For complex reporting (multiple aggregates like counts, sums, histograms in single query), $facet + $bucket / $bucketAuto is powerful.
// - If you need time-series or running totals / moving averages, use newer window-stage operators (e.g. $setWindowFields) where MongoDB version supports them.


// ================================
// SAMPLE SCHEMA & DATA (for testing some of above queries) â€” you can adapt to your collections
/*
use shopDB;

db.customers.insertMany([
  { _id: 1, name: "Alice", age: 30, spending: 1200 },
  { _id: 2, name: "Bob",   age: 22, spending: 800 },
  { _id: 3, name: "Charlie", age: 40, spending: 1500 },
  // ... more docs
]);

db.orders.insertMany([
  { _id: 101, customerId: 1, amount: 300, status: "completed", orderDate: ISODate("2025-02-10") },
  { _id: 102, customerId: 2, amount: 450, status: "pending",   orderDate: ISODate("2025-03-01") },
  { _id: 103, customerId: 1, amount: 700, status: "completed", orderDate: ISODate("2025-04-15") },
  // ... more orders
]);

db.sales.insertMany([
  { _id: 201, productId: "P1", date: ISODate("2025-01-05"), amount: 200, quantity: 2 },
  { _id: 202, productId: "P1", date: ISODate("2025-01-15"), amount: 300, quantity: 3 },
  { _id: 203, productId: "P2", date: ISODate("2025-02-10"), amount: 500, quantity: 5 },
  // ... more sales data
]);
*/





// ================================
// MongoDB â€” More Advanced Aggregation & Query Examples + Notes
// (extensions: recursive lookup, array-filtering, nested lookups, conditional logic, materialization, etc.)
// ================================

// === More Advanced / Less-common Aggregation Stages & Use-Cases ===

1. Recursive / Graph-style lookup within a collection (hierarchies / tree / graph data) â€” using $graphLookup
db.employees.aggregate([
  {
    $graphLookup: {
      from: "employees",
      startWith: "$managerId",
      connectFromField: "managerId",
      connectToField: "_id",
      as: "managementChain",
      maxDepth: 5,                // optional: limit recursion depth
      depthField: "level"         // optional: track how far the node is from start
    }
  }
]);

// e.g. output: each employee doc gets a field â€œmanagementChainâ€ as an array of all their managers / ancestors.

2. Filtering or manipulating array-fields inside documents (e.g. selecting subset of array elements) + aggregation

// Suppose a doc structure: { _id, name, scores: [ { subject: "math", score: 80 }, { subject: "eng", score: 65 }, ... ] }
// We can compute average for only certain subjects (e.g. where score > 70):

db.students.aggregate([
  { $project: {
      name: 1,
      highScores: {
        $filter: {
          input: "$scores",
          as: "s",
          cond: { $gt: ["$$s.score", 70] }
        }
      }
    }
  },
  { $unwind: "$highScores" },
  { $group: {
      _id: "$_id",
      avgHighScore: { $avg: "$highScores.score" }
    }
  }
]);

// This gives, per student, the average of only â€œhighâ€ scores. (You can adapt the condition.)  
// This pattern helps when you need array-level filtering + aggregation.  

3. Nested / multi-level lookups (join across multiple collections, then aggregate)  
// Example: Suppose we have collection â€œordersâ€ referencing â€œcustomersâ€, and each customer references â€œregionâ€. Want to get, per region, total sales.

db.orders.aggregate([
  { $match: { status: "completed" } },
  { $lookup: {
      from: "customers",
      localField: "customerId",
      foreignField: "_id",
      as: "cust"
    }
  },
  { $unwind: "$cust" },
  { $lookup: {
      from: "regions",
      localField: "cust.regionId",
      foreignField: "_id",
      as: "region"
    }
  },
  { $unwind: "$region" },
  { $group: {
      _id: "$region.name",
      totalSales: { $sum: "$amount" },
      orderCount: { $sum: 1 }
    }
  },
  { $sort: { totalSales: -1 } }
]);



nested lookup example:
[
  {
    $lookup: {
      from: "customers",
      let: { custId: "$customerId" },        // pass value into sub-pipeline
      pipeline: [
        {
          $match: {
            $expr: { $eq: ["$_id", "$$custId"] }
          }
        }
      ],
      as: "cust"
    }
  },
  { $unwind: "$cust" },

  {
    $lookup: {
      from: "regions",
      let: { regionId: "$cust.regionId" },   // pass nested field  
      pipeline: [
        {
          $match: {
            $expr: { $eq: ["$_id", "$$regionId"] }
          }
        }
      ],
      as: "region"
    }
  },
  { $unwind: "$region" }
]


// This gives per-region aggregated sales â€” demonstrates chaining lookups + group.  

4. Conditional logic inside aggregation â€” e.g. categorize data, compute conditional sums / counts  
// Suppose you have orders with an amount field, and you want to bucket into â€œsmallâ€, â€œmediumâ€, â€œlargeâ€ orders, then count each category:

db.orders.aggregate([
  { $project: {
      amount: 1,
      sizeCategory: {
        $switch: {
          branches: [
            { case: { $lte: ["$amount", 100] }, then: "small" },
            { case: { $and: [ { $gt: ["$amount", 100] }, { $lte: ["$amount", 500] } ] }, then: "medium" },
            { case: { $gt: ["$amount", 500] }, then: "large" }
          ],
          default: "unknown"
        }
      }
    }
  },
  { $group: {
      _id: "$sizeCategory",
      count: { $sum: 1 },
      totalAmount: { $sum: "$amount" }
    }
  }
]);

// This lets you categorize and aggregate in one pipeline â€” useful for quick reports / segmentation.  

5. Combining multiple analytics: e.g. count, sum, average, distinct values â€” using $facet + $group + $addToSet  

db.orders.aggregate([
  { $facet: {
      summary: [
        { $group: { _id: null, totalOrders: { $sum: 1 }, totalRevenue: { $sum: "$amount" } } }
      ],
      avgOrder: [
        { $group: { _id: null, avgAmount: { $avg: "$amount" } } }
      ],
      customers: [
        { $group: { _id: "$customerId" } },
        { $count: "distinctCustomerCount" }
      ],
      bucketedByAmount: [
        { $bucket: {
            groupBy: "$amount",
            boundaries: [0, 100, 500, 1000, 5000],
            default: "5000+",
            output: {
              count: { $sum: 1 },
              total: { $sum: "$amount" }
            }
          }
        }
      ]
    }
  }
]);

// This returns a document having multiple analytics (summary, avg, distinct count, bucket-histogram) â€” very useful for dashboards / reporting.  

6. Materializing aggregated results into another collection â€” using $merge (or $out) â€” useful for reports / summary tables / caching  

db.sales.aggregate([
  { $group: { _id: "$productId", totalQty: { $sum: "$quantity" }, totalAmount: { $sum: "$amount" } } },
  { $merge: {
      into: "productSalesSummary",
      whenMatched: "merge",        // merge with existing doc if present
      whenNotMatched: "insert"     // insert new doc if not exist
    }
  }
]);

// Now â€œproductSalesSummaryâ€ has one doc per productId with aggregated totals â€” can be used for fast lookups later.  

7. Handling large data sets â€” using allowDiskUse, early $match, limiting fields  

db.bigCollection.aggregate([
  { $match: { status: "active", createdAt: { $gte: ISODate("2025-01-01") } } },
  { $project: { field1: 1, field2: 1 /* only necessary fields */ } },
  { /* further heavy operations like $group / $lookup / $sort */ }
], { allowDiskUse: true });

// Setting allowDiskUse helps avoid memory errors / limit issues on big pipelines.  

// ================================
// Extended Theory / Interview-level Concepts & Edge Cases to Know
// ================================

// â€¢ Recursive / graph-structured data traversal: using $graphLookup â€” for organizational charts, hierarchies, tree- or graph-like data structures. Understand parameters like startWith, connectFromField/connectToField, maxDepth, depthField, and memory/disk usage constraints. :contentReference[oaicite:2]{index=2}

// â€¢ Array-filtering + aggregation: using $filter, $unwind + $group â€” when documents have embedded arrays and you need to filter & aggregate based on array contents. Useful for scores, tags, history arrays, etc.  

// â€¢ Multi-level joins / nested lookups: when documents reference other collections (and those further reference others). Understand the performance implications, and when embedding vs referencing makes sense.  

// â€¢ Conditional aggregation / bucketing inside aggregation â€” using $switch / $cond / $bucket / $bucketAuto â€” for segmentation, categorization, histograms.  

// â€¢ Faceted aggregation / dashboards â€” using $facet to compute multiple independent aggregations in a single pass â€” efficient for reporting or analytics endpoints.

// â€¢ Materializing aggregated output â€” using $merge / $out â€” to build summary collections / materialized views inside MongoDB, useful in analytics-heavy applications.  

// â€¢ Performance & resource constraints: when pipelines become heavy (joins, recursion, large data, grouping) â€” need proper indexing, early filtering ($match), projecting only necessary fields, possibly use allowDiskUse, understand memory limits and disk spill behaviour.  

// â€¢ Schema design considerations given advanced queries: if you have frequent nested lookups or graph-like relations, sometimes embedding or denormalizing can give better performance than frequent $lookup/$graphLookup. Also consider tradeoffs (data duplication vs query performance).  

// â€¢ Awareness of MongoDB version / feature support: e.g. $graphLookup, $bucketAuto, $merge â€” only available in certain versions; likewise behaviour of memory, sharding with $graphLookup, etc. Always check version compatibility.


âœ… MongoDB Advanced Concepts â€” Problem & Solution Based Understanding
1. Replica Set (High Availability)
â— Problem

What happens if your database server suddenly goes down?

Your app cannot read/write.

Users face downtime.

Possible data loss if the server crashes.

âœ… MongoDB Solution â€” Replica Set

MongoDB keeps multiple copies of your data on different servers.

Primary = handles writes

Secondaries = copy data from primary

Arbiter = votes during elections but stores no data

If the primary fails:

A secondary becomes new primary automatically

No manual restart required â†’ high availability

ğŸ“Œ Simple Example
Primary goes down â†’ Election happens â†’ Secondary becomes Primary â†’ App continues

âš ï¸ Trade-offs

Reads from secondary may show old data (eventual consistency).

Replication lag during heavy writes.

2. Sharding (Horizontal Scaling)
â— Problem

What if:

Your data is too large for a single machine?

Traffic is too high?

Reads/writes become slow?

A single MongoDB server wonâ€™t handle it.

âœ… MongoDB Solution â€” Sharding

MongoDB splits your data across multiple servers using a shard key.

Example:

Users with id 1â€“1000 â†’ shard 1
Users with id 1001â€“2000 â†’ shard 2

Components

Shards â†’ actual data

Config servers â†’ metadata

mongos router â†’ routes queries to correct shard

ğŸ“Œ Example

If you search for user with id = 1500,
mongos knows it belongs to Shard 2 only â†’ fast.

âš ï¸ Trade-offs

Hard to change shard key later.

Bad shard key â†’ "hot shard" (all writes go to same shard).

Increased operational complexity.

3. Storage Engines (WiredTiger)
â— Problem

Old storage engines (like MMAPv1) had:

High locking (collection-level)

High memory usage

No compression

This caused slow performance.

âœ… MongoDB Solution â€” WiredTiger

WiredTiger provides:

Document-level concurrency â†’ multiple writes at same time

Compression â†’ saves disk

Journaling â†’ prevents data loss

ğŸ“Œ Example

Two users updating different documents can do so without blocking each other.

âš ï¸ When it matters

Write-heavy apps

Multi-user environments

Large datasets

4. Transactions (ACID)
â— Problem

What if you need:

Multiple writes to succeed together

Or fail together?

Example:

Transfer money: deduct from A, add to B.


Both must succeed or fail.

MongoDB originally only allowed single-document atomicity.

âœ… MongoDB Solution â€” Multi-document Transactions

Since v4.0, MongoDB supports:

ACID guarantees

Multi-document transactions

Transactions in sharded clusters

ğŸ“Œ Example
session.startTransaction();
// deduct from A
// add to B
session.commitTransaction();

âš ï¸ Trade-offs

Slower performance

More memory overhead

Should be used only when necessary

Usually better to embed data and avoid transactions.

5. Aggregation Pipeline
â— Problem

Simple queries cannot:

Group data

Calculate sums/averages

Transform documents

Do analytics

âœ… MongoDB Solution â€” Aggregation Pipeline

Think of it like a data processing pipeline:

match â†’ group â†’ project â†’ sort â†’ limit

ğŸ“Œ Example

Find total sales per product:

[
  { $group: { _id: "$product", total: { $sum: "$amount" } } }
]

âš ï¸ Trade-offs

Uses more memory

May require allowDiskUse

Slow without indexes

6. Capped Collections
â— Problem

Logs grow forever â†’ disk fills up.

âœ… MongoDB Solution â€” Capped Collections

A capped collection:

Has fixed size

Overwrites oldest data

Preserves insertion order

ğŸ“Œ Example

A 1GB capped log collection will always stay 1GB.

Use cases

Logs

Events

Real-time data streams

7. Covered Query
â— Problem

MongoDB normally reads the document from disk â†’ slower.

What if we could answer a query using only the index?
âœ… MongoDB Solution â€” Covered Query

If:

Query uses indexed fields

Projection uses indexed fields

MongoDB does not need to fetch document â†’ super fast.

ğŸ“Œ Example

Index:

{ name: 1, age: 1 }


Query:

find({ name: "John" }, { age: 1 })


All fields are in index â†’ covered.

8. Embedding vs Referencing
â— Problem

How should you store related data?

Together?

Or separately?

Option 1: Embedding

Store child data inside parent document.

ğŸ“Œ Example
{
  name: "John",
  orders: [{ id: 1, amount: 100 }]
}

Pros

Fast reads (one query)

Atomic updates

Cons

Large document size

Duplicate data

Option 2: Referencing

Store them separately with IDs.

ğŸ“Œ Example

users and orders collection with userId.

Pros

Good for large data

Avoid duplication

Cons

Requires join ($lookup)

More queries

9. Sharded Cluster Architecture
â— Problem

Need both scaling + high availability.

MongoDBâ€™s Solution

3 parts:

Shard â†’ holds data

Config servers â†’ metadata (chunk info)

mongos â†’ router

ğŸ“Œ What happens when data grows?

Chunks move between shards to balance load.

âš ï¸ Trade-offs

Operational complexity

Slow cross-shard queries

10. TTL Index
â— Problem

Need data to expire after time:

Sessions

Temporary tokens

Old logs

MongoDB Solution â€” TTL Index

MongoDB automatically deletes documents after X seconds.

ğŸ“Œ Example
{ createdAt: 1 }, expireAfterSeconds: 3600


Deletes doc after 1 hour.

11. Index Types
â— Problem

Slow queries due to no indexes.

MongoDB Solution â€” Many index types

Single-field

Compound

Text

Geospatial

Hashed

TTL

Wildcard

ğŸ“Œ Why indexing helps

Indexes reduce scanned documents:

From 1M documents â†’ To 10 indexed entries

âš ï¸ Trade-offs

Slower writes

More RAM usage

12. Backup & Restore
â— Problem

What if server crashes? Data corruption? Need historical data?

Solutions

mongodump/mongorestore

File system snapshots

Backups from secondaries

Atlas cloud backups

Challenge

Sharded clusters require consistent backups across shards.

13. Security Best Practices
â— Problem

By default, MongoDB was often left open to the internet â†’ hacks & leaks.

MongoDB Solutions

Enable authentication

Use TLS/SSL

Role-based access control

IP whitelisting

Encryption at rest

Disable external access

14. When MongoDB is NOT a Good Fit
â— Problem

MongoDB is great but not for everything.

Not ideal for:

Complex joins (many-to-many)

Highly relational data

Heavy ACID requirements

High consistency needs

OLAP queries

15. Data Modeling in MongoDB vs SQL
â— Problem

SQL normalizes, MongoDB does not.

MongoDB Approach

Model for queries

Embed when reading together

Reference when child data is too large or shared

Use schema flexibility

Plan shard key early

